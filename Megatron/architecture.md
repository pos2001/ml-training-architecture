
###Megatron-LM은 NVIDIA에서 개발한 대규모 언어 모델 학습을 위한 프레임워크입니다:

주요 특징	설명

<img width="339" height="115" alt="image" src="https://github.com/user-attachments/assets/a6d45d6f-c5ac-48fe-8958-965013648f00" />




## Megatron 분산 학습: 완전한 아키텍처 (연결 포함)
### 전체 시스템 구조
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              HEAD NODE (m5.8xlarge)                          │
│                              IP: 10.0.31.195                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  HOST OS (Ubuntu 22.04)                                                      │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  Slurm Controller (slurmctld) - PID: 1234                          │    │
│  │  ├─ 작업 스케줄링 및 큐 관리                                        │    │
│  │  ├─ 리소스 할당 (GPU, 메모리, 네트워크)                            │    │
│  │  ├─ 노드 헬스 체크                                                  │    │
│  │  └─ 작업 상태 모니터링                                              │    │
│  └────────────────────────────────────────────────────────────────────┘    │
│                                                                              │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  Pyxis (Slurm Plugin) - 컨테이너 통합                              │    │
│  │  ├─ srun --container-image 처리                                    │    │
│  │  ├─ Enroot 호출 및 관리                                             │    │
│  │  ├─ GPU/디바이스 마운트 설정                                        │    │
│  │  └─ 환경 변수 전달                                                  │    │
│  └────────────────────────────────────────────────────────────────────┘    │
│                                                                              │
│  사용자 세션 (ubuntu)                                                        │
│  $ cd /fsx                                                                   │
│  $ srun --nodes=2 \                                                          │
│         --ntasks=16 \                                                        │
│         --ntasks-per-node=8 \                                                │
│         --gpus-per-node=8 \                                                  │
│         --container-image=/fsx/megatron-training.sqsh \                     │
│         --container-mounts=/fsx:/fsx,/dev/infiniband:/dev/infiniband \      │
│         python /workspace/Megatron-LM/pretrain_gpt.py                       │
│                                                                              │
│  리소스:                                                                     │
│  ├─ CPU: 32 vCPUs                                                           │
│  ├─ RAM: 128 GB                                                             │
│  ├─ GPU: 없음 ❌                                                            │
│  └─ Network: 10 Gbps Ethernet                                               │
│                                                                              │
│  마운트:                                                                     │
│  └─ /fsx (FSx Lustre via NFS)                                               │
│                                                                              │
└──────────────────────────────────┬───────────────────────────────────────────┘
                                   │
                                   │ Slurm RPC (TCP/IP)
                                   │ - 작업 제출
                                   │ - 리소스 요청
                                   │ - 상태 업데이트
                                   │
                    ┌──────────────┴──────────────┐
                    │                             │
                    ▼                             ▼
          ┌─────────────────┐           ┌─────────────────┐
          │ Compute Node 1  │           │ Compute Node 2  │
          │ 10.1.45.166     │           │ 10.1.57.162     │
          └─────────────────┘           └─────────────────┘

```




### 공유 스토리지 (FSx Lustre)
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         SHARED STORAGE (/fsx)                                │
│                         FSx Lustre - 1.2 TB                                  │
│                         Lustre MGS/MDS: 10.1.18.248                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  /fsx/                                                                       │
│  ├─ megatron-training.sqsh ◄───────────────────┐                           │
│  │  (Squashfs 컨테이너 이미지, 5 GB)           │                           │
│  │  ┌──────────────────────────────────────┐   │                           │
│  │  │ 레이어 구조:                          │   │                           │
│  │  │ ├─ Base: Ubuntu 22.04                │   │                           │
│  │  │ ├─ Python 3.10                       │   │                           │
│  │  │ ├─ PyTorch 2.0.1                     │   │                           │
│  │  │ ├─ CUDA Toolkit 12.2                 │   │                           │
│  │  │ ├─ NCCL 2.18.5-1+cuda12.2            │   │                           │
│  │  │ ├─ AWS OFI NCCL v1.8.1-aws           │   │                           │
│  │  │ ├─ Megatron-LM 코드                  │   │                           │
│  │  │ ├─ Apex (mixed precision)            │   │                           │
│  │  │ └─ 기타 의존성 라이브러리             │   │                           │
│  │  └──────────────────────────────────────┘   │                           │
│  │                                              │                           │
│  ├─ data/                                       │ 모든 노드가 동시 접근     │
│  │  ├─ train_data.bin (100 GB)                 │ (Lustre 병렬 I/O)         │
│  │  └─ train_data.idx                          │                           │
│  │                                              │                           │
│  ├─ checkpoints/                                │                           │
│  │  ├─ iter_0001000/                           │                           │
│  │  │   ├─ mp_rank_00_model_states.pt          │                           │
│  │  │   ├─ mp_rank_01_model_states.pt          │                           │
│  │  │   └─ ... (16개 샤드)                     │                           │
│  │  └─ iter_0002000/                           │                           │
│  │                                              │                           │
│  ├─ logs/                                       │                           │
│  │  ├─ train_20231205.log                      │                           │
│  │  └─ tensorboard/                            │                           │
│  │                                              │                           │
│  └─ scripts/                                    │                           │
│     └─ train.sh                                 │                           │
│                                                 │                           │
│  마운트 정보:                                    │                           │
│  ├─ Head Node:    /fsx (NFS 4.2)               │                           │
│  ├─ Compute Node 1: /fsx (Lustre client)       │                           │
│  └─ Compute Node 2: /fsx (Lustre client)       │                           │
│                                                 │                           │
│  성능:                                           │                           │
│  └─ Aggregate 대역폭: ~수백 GB/s (병렬 접근)    │                           │
│                                                 │                           │
└─────────────────────────────────────────────────┼───────────────────────────┘
                                                  │
                                                  │ Lustre Protocol
                                                  │ (이미지 읽기, 데이터 로드)
                                                  │
                    ┌─────────────────────────────┴─────────────────────────┐
                    │                                                       │
                    ▼                                                       ▼

```


### 컴퓨트 노드
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   COMPUTE NODE 1 (p5.48xlarge)                               │
│                   IP: 10.1.45.166                                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  HOST OS (Ubuntu 22.04)                                                      │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  시스템 데몬 및 드라이버:                                           │    │
│  │  ├─ Slurm Daemon (slurmd) - PID: 2000                             │    │
│  │  │   ├─ slurmctld와 통신 (TCP/IP)                                 │    │
│  │  │   ├─ 작업 수신 및 실행                                          │    │
│  │  │   ├─ 리소스 모니터링                                            │    │
│  │  │   └─ Pyxis 플러그인 로드                                        │    │
│  │  │                                                                 │    │
│  │  ├─ Pyxis (Slurm Plugin)                                           │    │
│  │  │   ├─ Enroot 컨테이너 생성 관리                                 │    │
│  │  │   ├─ --container-image 파싱                                    │    │
│  │  │   ├─ --container-mounts 처리                                   │    │
│  │  │   └─ GPU/디바이스 바인딩                                        │    │
│  │  │                                                                 │    │
│  │  ├─ Enroot 3.4.1                                                   │    │
│  │  │   ├─ Squashfs 이미지 마운트                                     │    │
│  │  │   ├─ 컨테이너 네임스페이스 생성                                 │    │
│  │  │   └─ 프로세스 격리                                              │    │
│  │  │                                                                 │    │
│  │  ├─ CUDA Driver 550.90.07                                          │    │
│  │  │   └─ 8 x H100 GPU 제어                                         │    │
│  │  │                                                                 │    │
│  │  ├─ EFA Driver 1.26.1                                              │    │
│  │  │   ├─ 32 x EFA 인터페이스 (각 100 Gbps)                         │    │
│  │  │   ├─ RDMA 지원 (GPUDirect)                                     │    │
│  │  │   └─ libfabric 통합                                            │    │
│  │  │                                                                 │    │
│  │  └─ /fsx 마운트 (Lustre client)                                   │    │
│  │      └─ 10.1.18.248@tcp:/igm4lbev                                 │    │
│  └────────────────────────────────────────────────────────────────────┘    │
│                                                                              │
│  리소스:                                                                     │
│  ├─ CPU: 192 vCPUs (2 x 96-core AMD EPYC)                                  │
│  ├─ RAM: 2 TB (1992 GB)                                                    │
│  ├─ GPU: 8 x NVIDIA H100 80GB HBM3                                         │
│  ├─ NVMe: 8 x 3.84 TB = 30.72 TB (/scratch)                                │
│  └─ Network: 32 x EFA (3200 Gbps = 400 GB/s aggregate)                     │
│                                                                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  Enroot Container Instance #1                                      │    │
│  │  프로세스: PID 10001 (Rank 0, Local Rank 0)                        │    │
│  │  ┌──────────────────────────────────────────────────────────┐     │    │
│  │  │  컨테이너 생성 과정:                                      │     │    │
│  │  │  1. Pyxis가 Enroot 호출                                  │     │    │
│  │  │  2. /fsx/megatron-training.sqsh 마운트                   │     │    │
│  │  │  3. 네임스페이스 생성 (PID, Mount, Network)              │     │    │
│  │  │  4. 디바이스 바인딩                                       │     │    │
│  │  │     ├─ /dev/nvidia0 → GPU 0                             │     │    │
│  │  │     ├─ /dev/infiniband → EFA RDMA                       │     │    │
│  │  │     └─ /fsx → 공유 스토리지                             │     │    │
│  │  │  5. 환경 변수 설정                                        │     │    │
│  │  │  6. python 프로세스 시작                                 │     │    │
│  │  └──────────────────────────────────────────────────────────┘     │    │
│  │                                                                     │    │
│  │  실행 중인 프로세스:                                                │    │
│  │  └─ python (PID: 10001)                                            │    │
│  │     └─ /workspace/Megatron-LM/pretrain_gpt.py                     │    │
│  │        ├─ PyTorch 런타임                                           │    │
│  │        ├─ CUDA Context (GPU 0)                                    │    │
│  │        ├─ NCCL Communicator                                        │    │
│  │        │   ├─ 로컬 통신: NVLink (GPU 0-7)                         │    │
│  │        │   └─ 원격 통신: EFA (Node 1 ↔ Node 2)                   │    │
│  │        └─ 데이터 로더 (multiprocessing)                           │    │
│  │                                                                     │    │
│  │  환경 변수:                                                         │    │
│  │  ├─ RANK=0                                                         │    │
│  │  ├─ WORLD_SIZE=16                                                  │    │
│  │  ├─ LOCAL_RANK=0                                                   │    │
│  │  ├─ CUDA_VISIBLE_DEVICES=0                                         │    │
│  │  ├─ MASTER_ADDR=10.1.45.166                                        │    │
│  │  ├─ MASTER_PORT=29500                                              │    │
│  │  ├─ NCCL_DEBUG=INFO                                                │    │
│  │  ├─ NCCL_NET_GDR_LEVEL=3                                           │    │
│  │  ├─ FI_PROVIDER=efa                                                │    │
│  │  ├─ FI_EFA_USE_DEVICE_RDMA=1                                       │    │
│  │  └─ LD_LIBRARY_PATH=/opt/amazon/efa/lib:...                       │    │
│  │                                                                     │    │
│  │  컨테이너 마운트:                                                   │    │
│  │  ├─ / (rootfs) ← /fsx/megatron-training.sqsh (읽기 전용)          │    │
│  │  ├─ /dev/nvidia0 ← HOST:/dev/nvidia0                              │    │
│  │  ├─ /dev/infiniband ← HOST:/dev/infiniband                        │    │
│  │  ├─ /opt/amazon/efa ← HOST:/opt/amazon/efa                        │    │
│  │  ├─ /opt/amazon/ofi-nccl ← HOST:/opt/amazon/ofi-nccl              │    │
│  │  └─ /fsx ← HOST:/fsx (Lustre)                                     │    │
│  │                                                                     │    │
│  │  메모리 사용:                                                       │    │
│  │  ├─ CPU RAM: ~50 GB                                                │    │
│  │  │   ├─ Python 런타임: ~2 GB                                      │    │
│  │  │   ├─ PyTorch 라이브러리: ~5 GB                                 │    │
│  │  │   ├─ 데이터 로더 버퍼: ~20 GB                                  │    │
│  │  │   ├─ NCCL 통신 버퍼: ~10 GB                                    │    │
│  │  │   └─ 기타: ~13 GB                                              │    │
│  │  │                                                                 │    │
│  │  └─ GPU 0 VRAM: ~70 GB / 80 GB                                    │    │
│  │      ├─ 모델 파라미터: ~20 GB (1/16 샤드)                         │    │
│  │      ├─ Gradient 버퍼: ~20 GB                                     │    │
│  │      ├─ Optimizer 상태: ~20 GB (Adam: 2x params)                 │    │
│  │      └─ Activation 값: ~10 GB                                     │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                              │                                               │
│                              │ CUDA API 호출                                 │
│                              │ cudaMalloc, cudaMemcpy, cudaLaunchKernel     │
│                              ▼                                               │
│                          GPU 0 (H100)                                        │
│                          └─ 80 GB HBM3, 1000 GB/s 메모리 대역폭             │
│                                                                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  Enroot Container Instance #2                                      │    │
│  │  프로세스: PID 10002 (Rank 1, Local Rank 1)                        │    │
│  │  ├─ 이미지: /fsx/megatron-training.sqsh                           │    │
│  │  ├─ RANK=1, CUDA_VISIBLE_DEVICES=1                                │    │
│  │  └─ 마운트: /dev/nvidia1, /dev/infiniband, /fsx                   │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                              ▼ GPU 1 (H100)                                  │
│                                                                              │
├──────────────────────────────────────────────────────────────────────────────┤
│  ... (Container #3-#7: Rank 2-6, GPU 2-6)                                   │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌────────────────────────────────────────────────────────────────────┐    │
│  │  Enroot Container Instance #8                                      │    │
│  │  프로세스: PID 10008 (Rank 7, Local Rank 7)                        │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                              ▼ GPU 7 (H100)                                  │
│                                                                              │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  GPU Topology (NVSwitch - Full Mesh):                                       │
│  ┌──────────────────────────────────────────────────────────────────┐      │
│  │  GPU 0 ◄───────────────────────────────────────┐                 │      │
│  │  GPU 1 ◄─────────────────────────────────┐     │                 │      │
│  │  GPU 2 ◄───────────────────────────┐     │     │                 │      │
│  │  GPU 3 ◄─────────────────────┐     │     │     │  NVLink 4.0    │      │
│  │  GPU 4 ◄───────────────┐     │     │     │     │  18 links/GPU  │      │
│  │  GPU 5 ◄─────────┐     │     │     │     │     │  900 GB/s      │      │
│  │  GPU 6 ◄───┐     │     │     │     │     │     │  bidirectional │      │
│  │  GPU 7 ◄─┐ │     │     │     │     │     │     │                 │      │
│  │          │ │     │     │     │     │     │     │  All-to-All    │      │
│  │          └─┴─────┴─────┴─────┴─────┴─────┴─────┘  연결          │      │
│  └──────────────────────────────────────────────────────────────────┘      │
│                                                                              │
│  EFA Network Interfaces:                                                     │
│  ├─ rdmap79s0, rdmap80s0, ..., rdmap201s0 (32개 RDMA 디바이스)             │
│  ├─ 각 100 Gbps (12.5 GB/s)                                                │
│  └─ 총 3200 Gbps (400 GB/s) aggregate 대역폭                               │
│                                                                              │
└──────────────────────────────────┬───────────────────────────────────────────┘
                                   │
                                   │ EFA Network
                                   │ (물리적 네트워크 케이블)
                                   │ 3200 Gbps bidirectional
                                   │
                                   ▼

```
