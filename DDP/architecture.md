

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
분산 학습: 여러 컴퓨터가 협력하여 AI 학습
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

컴퓨터 1 (Node 1)              컴퓨터 2 (Node 2)
┌─────────────────┐            ┌─────────────────┐
│  PyTorch 환경   │            │  PyTorch 환경   │
│                 │            │                 │
│  GPU 0: 데이터 A │            │  GPU 4: 데이터 E │
│  GPU 1: 데이터 B │            │  GPU 5: 데이터 F │
│  GPU 2: 데이터 C │            │  GPU 6: 데이터 G │
│  GPU 3: 데이터 D │            │  GPU 7: 데이터 H │
└────────┬────────┘            └────────┬────────┘
         │                              │
         │  Gloo (통신)                 │
         │  ←───────────────────────→   │
         │                              │
         └──────────┬───────────────────┘
                    ↓
            모든 GPU가 학습 결과 공유
            → 모델이 일관되게 학습됨

프로세스:
1. 각 GPU가 데이터 일부를 받음
2. 동시에 학습 진행
3. 결과를 서로 공유 (Gloo 통신)
4. 모델 업데이트
5. 반복

결과: 8배 빠른 학습! ⚡
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

```





```
┌─────────────────────────────────────────────────────────────────┐
│                   분산 학습 아키텍처 (DDP)                       │
└─────────────────────────────────────────────────────────────────┘

┌──────────────────────────────┐    ┌──────────────────────────────┐
│        Node 1 (서버 1)        │    │        Node 2 (서버 2)        │
│                              │    │                              │
│  ┌────────────────────────┐ │    │  ┌────────────────────────┐ │
│  │ pytorch_squash.sqsh    │ │    │  │ pytorch_squash.sqsh    │ │
│  │ (컨테이너 이미지)       │ │    │  │ (컨테이너 이미지)       │ │
│  │                        │ │    │  │                        │ │
│  │  Python + PyTorch      │ │    │  │  Python + PyTorch      │ │
│  │  + Gloo (통신 라이브러리)│ │    │  │  + Gloo (통신 라이브러리)│ │
│  └────────────────────────┘ │    │  └────────────────────────┘ │
│                              │    │                              │
│  ┌────────────────────────┐ │    │  ┌────────────────────────┐ │
│  │      ddp.py            │ │    │  │      ddp.py            │ │
│  │  (분산 학습 스크립트)   │ │    │  │  (분산 학습 스크립트)   │ │
│  └────────────────────────┘ │    │  └────────────────────────┘ │
│                              │    │                              │
│  ┌─────┬─────┬─────┬─────┐ │    │  ┌─────┬─────┬─────┬─────┐ │
│  │ P0  │ P1  │ P2  │ P3  │ │    │  │ P4  │ P5  │ P6  │ P7  │ │
│  │GPU 0│GPU 1│GPU 2│GPU 3│ │    │  │GPU 0│GPU 1│GPU 2│GPU 3│ │
│  └─────┴─────┴─────┴─────┘ │    │  └─────┴─────┴─────┴─────┘ │
│         ↓                   │    │         ↓                   │
│    각 GPU가 데이터 일부 처리 │    │    각 GPU가 데이터 일부 처리 │
└──────────────┬───────────────┘    └──────────────┬───────────────┘
               │                                   │
               │    Gloo를 통한 통신 (네트워크)     │
               │  ←─────────────────────────────→  │
               │                                   │
               └───────────────┬───────────────────┘
                               ↓
                      그래디언트 동기화
                   (모든 GPU가 학습 결과 공유)

```

```
PyTorch:
• AI/딥러닝 프레임워크
• 모델 학습 담당

Gloo:
• Facebook(Meta)이 개발한 통신 라이브러리
• 노드 간 데이터 교환 담당

역할:
┌──────────┐     Gloo      ┌──────────┐
│ Node 1   │ ←─────────→   │ Node 2   │
│ 학습 결과 │   빠른 통신    │ 학습 결과 │
└──────────┘               └──────────┘

```


```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                         분산 학습 전체 아키텍처
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

┌────────────────────────────────────────────────────────────────────────────┐
│                         공유 스토리지 (Shared Storage)                      │
│                    예: NFS, Amazon FSx for Lustre, S3                       │
├────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│  📦 pytorch_squash.sqsh                                                    │
│     (컨테이너 이미지: Python + PyTorch + Gloo + 라이브러리)                  │
│     크기: 수 GB                                                             │
│                                                                            │
│  📄 ddp.py                                                                 │
│     (학습 스크립트: 모델 정의, 학습 로직)                                    │
│     크기: 수십 KB ~ 수 MB                                                   │
│                                                                            │
│  📊 training_data/                                                         │
│     (학습 데이터셋)                                                          │
│     크기: 수십 GB ~ 수 TB                                                   │
│                                                                            │
│  💾 checkpoints/                                                           │
│     (학습 중간 저장 지점)                                                    │
│                                                                            │
└─────────────┬──────────────────────────────────────┬───────────────────────┘
              │                                      │
              │ 마운트/다운로드                        │ 마운트/다운로드
              │                                      │
    ┌─────────▼──────────────┐          ┌──────────▼─────────────┐
    │                        │          │                        │
    │      Node 1 (서버 1)    │          │      Node 2 (서버 2)    │
    │    IP: 10.0.1.10       │◄────────►│    IP: 10.0.1.11       │
    │                        │  Gloo    │                        │
    └────────────────────────┘  통신     └────────────────────────┘
    
    각 노드의 상세 구조 ▼

┌─────────────────────────────────────────────────────────────────────────────┐
│                              Node 1 (서버 1)                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  1️⃣ 초기화 단계: 공유 스토리지에서 파일 가져오기                              │
│  ┌────────────────────────────────────────────────────────────┐            │
│  │  공유 스토리지 마운트                                        │            │
│  │  /mnt/shared/ ← NFS/FSx 마운트                              │            │
│  │                                                             │            │
│  │  📦 /mnt/shared/pytorch_squash.sqsh  (읽기 전용)            │            │
│  │  📄 /mnt/shared/ddp.py               (읽기 전용)            │            │
│  │  📊 /mnt/shared/training_data/       (읽기 전용)            │            │
│  │  💾 /mnt/shared/checkpoints/         (읽기/쓰기)            │            │
│  └────────────────────────────────────────────────────────────┘            │
│                                                                             │
│  2️⃣ 컨테이너 실행 환경                                                       │
│  ┌────────────────────────────────────────────────────────────┐            │
│  │  Enroot/Singularity 컨테이너                                │            │
│  │  ┌──────────────────────────────────────────────────────┐ │            │
│  │  │  pytorch_squash.sqsh 마운트됨                        │ │            │
│  │  │  • Python 3.10                                       │ │            │
│  │  │  • PyTorch 2.x                                       │ │            │
│  │  │  • Gloo 통신 라이브러리                               │ │            │
│  │  │  • CUDA, cuDNN                                       │ │            │
│  │  │  • 기타 의존성 라이브러리                             │ │            │
│  │  └──────────────────────────────────────────────────────┘ │            │
│  └────────────────────────────────────────────────────────────┘            │
│                                                                             │
│  3️⃣ 학습 프로세스 실행 (각 GPU마다 1개)                                      │
│  ┌───────────────────┐  ┌───────────────────┐                             │
│  │   Process 0 (P0)  │  │   Process 1 (P1)  │                             │
│  │   Rank: 0         │  │   Rank: 1         │                             │
│  │ ┌───────────────┐ │  │ ┌───────────────┐ │                             │
│  │ │ python ddp.py │ │  │ │ python ddp.py │ │                             │
│  │ │ --rank 0      │ │  │ │ --rank 1      │ │                             │
│  │ └───────┬───────┘ │  │ └───────┬───────┘ │                             │
│  │         ↓         │  │         ↓         │                             │
│  │  ┌─────────────┐  │  │  ┌─────────────┐  │                             │
│  │  │   GPU 0     │  │  │  │   GPU 1     │  │                             │
│  │  │ • 모델 복사  │  │  │  │ • 모델 복사  │  │                             │
│  │  │ • 데이터 일부│  │  │  │ • 데이터 일부│  │                             │
│  │  │ • Forward   │  │  │  │ • Forward   │  │                             │
│  │  │ • Backward  │  │  │  │ • Backward  │  │                             │
│  │  └─────────────┘  │  │  └─────────────┘  │                             │
│  └───────────────────┘  └───────────────────┘                             │
│                                                                             │
│  ┌───────────────────┐  ┌───────────────────┐                             │
│  │   Process 2 (P2)  │  │   Process 3 (P3)  │                             │
│  │   Rank: 2         │  │   Rank: 3         │                             │
│  │ ┌───────────────┐ │  │ ┌───────────────┐ │                             │
│  │ │ python ddp.py │ │  │ │ python ddp.py │ │                             │
│  │ │ --rank 2      │ │  │ │ --rank 3      │ │                             │
│  │ └───────┬───────┘ │  │ └───────┬───────┘ │                             │
│  │         ↓         │  │         ↓         │                             │
│  │  ┌─────────────┐  │  │  ┌─────────────┐  │                             │
│  │  │   GPU 2     │  │  │  │   GPU 3     │  │                             │
│  │  │ • 모델 복사  │  │  │  │ • 모델 복사  │  │                             │
│  │  │ • 데이터 일부│  │  │  │ • 데이터 일부│  │                             │
│  │  │ • Forward   │  │  │  │ • Forward   │  │                             │
│  │  │ • Backward  │  │  │  │ • Backward  │  │                             │
│  │  └─────────────┘  │  │  └─────────────┘  │                             │
│  └───────────────────┘  └───────────────────┘                             │
│                                                                             │
│  4️⃣ 프로세스 간 통신 (노드 내부 - 빠름)                                      │
│  P0 ←──────→ P1 ←──────→ P2 ←──────→ P3                                    │
│  (GPU 간 통신: NVLink 또는 PCIe)                                            │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    │ Gloo 통신
                                    │ (네트워크: TCP/IP)
                                    │ 그래디언트 동기화
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Node 2 (서버 2)                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  1️⃣ 초기화 단계: 동일하게 공유 스토리지에서 파일 가져오기                      │
│  ┌────────────────────────────────────────────────────────────┐            │
│  │  공유 스토리지 마운트                                        │            │
│  │  /mnt/shared/ ← 동일한 NFS/FSx 마운트                       │            │
│  │                                                             │            │
│  │  📦 /mnt/shared/pytorch_squash.sqsh  (읽기 전용)            │            │
│  │  📄 /mnt/shared/ddp.py               (읽기 전용)            │            │
│  │  📊 /mnt/shared/training_data/       (읽기 전용)            │            │
│  │  💾 /mnt/shared/checkpoints/         (읽기/쓰기)            │            │
│  └────────────────────────────────────────────────────────────┘            │
│                                                                             │
│  2️⃣ 컨테이너 실행 환경 (Node 1과 동일)                                       │
│  ┌────────────────────────────────────────────────────────────┐            │
│  │  Enroot/Singularity 컨테이너                                │            │
│  │  ┌──────────────────────────────────────────────────────┐ │            │
│  │  │  pytorch_squash.sqsh 마운트됨                        │ │            │
│  │  │  (Node 1과 동일한 환경)                              │ │            │
│  │  └──────────────────────────────────────────────────────┘ │            │
│  └────────────────────────────────────────────────────────────┘            │
│                                                                             │
│  3️⃣ 학습 프로세스 실행 (각 GPU마다 1개, Rank 계속 이어짐)                     │
│  ┌───────────────────┐  ┌───────────────────┐                             │
│  │   Process 4 (P4)  │  │   Process 5 (P5)  │                             │
│  │   Rank: 4         │  │   Rank: 5         │                             │
│  │ ┌───────────────┐ │  │ ┌───────────────┐ │                             │
│  │ │ python ddp.py │ │  │ │ python ddp.py │ │                             │
│  │ │ --rank 4      │ │  │ │ --rank 5      │ │                             │
│  │ └───────┬───────┘ │  │ └───────┬───────┘ │                             │
│  │         ↓         │  │         ↓         │                             │
│  │  ┌─────────────┐  │  │  ┌─────────────┐  │                             │
│  │  │   GPU 0     │  │  │  │   GPU 1     │  │                             │
│  │  │ • 모델 복사  │  │  │  │ • 모델 복사  │  │                             │
│  │  │ • 데이터 일부│  │  │  │ • 데이터 일부│  │                             │
│  │  │ • Forward   │  │  │  │ • Forward   │  │                             │
│  │  │ • Backward  │  │  │ • Backward  │  │                             │
│  │  └─────────────┘  │  │  └─────────────┘  │                             │
│  └───────────────────┘  └───────────────────┘                             │
│                                                                             │
│  ┌───────────────────┐  ┌───────────────────┐                             │
│  │   Process 6 (P6)  │  │   Process 7 (P7)  │                             │
│  │   Rank: 6         │  │   Rank: 7         │                             │
│  │ ┌───────────────┐ │  │ ┌───────────────┐ │                             │
│  │ │ python ddp.py │ │  │ │ python ddp.py │ │                             │
│  │ │ --rank 6      │ │  │ │ --rank 7      │ │                             │
│  │ └───────┬───────┘ │  │ └───────┬───────┘ │                             │
│  │         ↓         │  │         ↓         │                             │
│  │  ┌─────────────┐  │  │  ┌─────────────┐  │                             │
│  │  │   GPU 2     │  │  │  │   GPU 3     │  │                             │
│  │  │ • 모델 복사  │  │  │  │ • 모델 복사  │  │                             │
│  │  │ • 데이터 일부│  │  │  │ • 데이터 일부│  │                             │
│  │  │ • Forward   │  │  │  │ • Forward   │  │                             │
│  │  │ • Backward  │  │  │  │ • Backward  │  │                             │
│  │  └─────────────┘  │  │  └─────────────┘  │                             │
│  └───────────────────┘  └───────────────────┘                             │
│                                                                             │
│  4️⃣ 프로세스 간 통신 (노드 내부)                                             │
│  P4 ←──────→ P5 ←──────→ P6 ←──────→ P7                                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                         Gloo 통신 (노드 간 그래디언트 동기화)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Node 1 (P0, P1, P2, P3)  ←──────────────────────→  Node 2 (P4, P5, P6, P7)
        │                   네트워크 (TCP/IP)                │
        │                   10Gbps ~ 100Gbps                │
        │                                                   │
        └───────────────── AllReduce 연산 ─────────────────┘
                    (모든 그래디언트 평균 계산 및 동기화)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

```




