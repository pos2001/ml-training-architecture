
## 5개 팀이 ParallelCluster 기반의 120대 P5 ODCR 사용하기

### 
```

```






### 배치 스크립트에서 특정 노드 지정
```
방법 1: --nodelist 옵션
#!/bin/bash
#SBATCH --job-name=teamA_training
#SBATCH --partition=gpu
#SBATCH --nodelist=gpu-dy-p5-[1-40]  # ✅ 1-40번 노드 지정
#SBATCH --nodes=40
#SBATCH --ntasks-per-node=8
#SBATCH --gpus-per-node=8
#SBATCH --time=48:00:00
#SBATCH --output=/fsx/logs/teamA_%j.out

srun python train.py --distributed


방법 2: -w 옵션 (단축형)
#!/bin/bash
#SBATCH --job-name=teamB_training
#SBATCH -w gpu-dy-p5-[41-80]  # ✅ 41-80번 노드 지정
#SBATCH --nodes=40
#SBATCH --ntasks-per-node=8
#SBATCH --gpus-per-node=8
#SBATCH --time=48:00:00

srun python train.py --distributed



방법 3: 명령줄에서 지정
# sbatch 명령 시 지정
sbatch --nodelist=gpu-dy-p5-[1-40] train.sh

# 또는
sbatch -w gpu-dy-p5-[1-40] train.sh

```

### 팀별 노드 할당 예시
```
# 팀별 노드 범위 합의
TeamA: gpu-dy-p5-[1-24]      # 24개
TeamB: gpu-dy-p5-[25-48]     # 24개
TeamC: gpu-dy-p5-[49-72]     # 24개
TeamD: gpu-dy-p5-[73-96]     # 24개
TeamE: gpu-dy-p5-[97-120]    # 24개

```





### ParallelCluster 멀티큐:
```
# 각 큐에 ODCR 분할 할당 (복잡)
SlurmQueues:
- Name: teamA
ComputeResources:
- Name: p5
MinCount: 24
MaxCount: 24
CapacityReservationTarget:
CapacityReservationId: cr-teamA  # 24대 ODCR

- Name: teamB
ComputeResources:
- Name: p5
MinCount: 24
MaxCount: 24
CapacityReservationTarget:
CapacityReservationId: cr-teamB  # 24대 ODCR

# 문제:
# - ODCR을 5개로 분할해야 함
# - 현재 120대 단일 ODCR이면 불가능

```






### 단일 큐 + Slurm Accounting 
```
이유:
1. ODCR이 단일 예약이므로 분할 불필요
2. Fair Share로 공정성 보장
3. 유연한 리소스 공유
4. 관리 복잡도 최소화

설정:
SlurmQueues:
- Name: gpu
ComputeResources:
- Name: p5
MinCount: 120
MaxCount: 120
CapacityReservationTarget:
CapacityReservationId: cr-xxxxx

```




### Slurm Partition 분할 (권장)
```
120대를 5개 파티션으로 나누기:

# slurm.conf 수정 (헤드노드에서)
sudo vi /opt/slurm/etc/slurm.conf

# 파티션 추가
PartitionName=teamA Nodes=gpu-dy-p5-[1-24] Default=NO MaxTime=INFINITE State=UP
PartitionName=teamB Nodes=gpu-dy-p5-[25-48] Default=NO MaxTime=INFINITE State=UP
PartitionName=teamC Nodes=gpu-dy-p5-[49-72] Default=NO MaxTime=INFINITE State=UP
PartitionName=teamD Nodes=gpu-dy-p5-[73-96] Default=NO MaxTime=INFINITE State=UP
PartitionName=teamE Nodes=gpu-dy-p5-[97-120] Default=NO MaxTime=INFINITE State=UP

# Slurm 재시작
sudo systemctl restart slurmctld
scontrol reconfigure

```






### 
```

```
