
## Head Node AMI ì˜µì…˜
<img width="883" height="184" alt="image" src="https://github.com/user-attachments/assets/c36e363b-b081-4d21-b6b5-f822b002925d" />

```
HeadNode:
InstanceType: c6i.xlarge
Networking:
SubnetId: subnet-xxxxx
# ì˜µì…˜ 1: í‘œì¤€ AMI (ê¸°ë³¸ê°’, ëª…ì‹œ ë¶ˆí•„ìš”)
# ParallelClusterê°€ ìë™ìœ¼ë¡œ ìµœì‹  í‘œì¤€ AMI ì„ íƒ

# ì˜µì…˜ 2: Custom AMI ì§€ì •
Image:
CustomAmi: ami-0123456789abcdef0

```


## Compute Node AMI ì˜µì…˜
<img width="878" height="223" alt="image" src="https://github.com/user-attachments/assets/d3735ce7-10f1-4d5f-9263-ea0baae33e47" />

### ParallelCluster í‘œì¤€ AMI (ê¸°ë³¸ ë°©ì‹)
```
íŠ¹ì§•:

    AWSê°€ ê³µì‹ ì œê³µ ë° ê´€ë¦¬
    ParallelCluster ë²„ì „ê³¼ í˜¸í™˜ì„± ë³´ì¥
    Slurm, PBS Pro, SGE ë“± ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ì „ ì„¤ì¹˜
    EFA, FSx Lustre ë“± AWS ì„œë¹„ìŠ¤ í†µí•©

Scheduling:
Scheduler: slurm
SlurmQueues:
- Name: compute
ComputeResources:
- Name: gpu-nodes
InstanceType: p5.48xlarge
MinCount: 0
MaxCount: 10
# AMI ì§€ì • ì•ˆ í•¨ = í‘œì¤€ AMI ìë™ ì‚¬ìš©

```




### DLAMI (Deep Learning AMI) ì‚¬ìš©
```
ì–¸ì œ ì‚¬ìš©í•˜ë‚˜:

    PyTorch, TensorFlow ë“± í”„ë ˆì„ì›Œí¬ ì‚¬ì „ ì„¤ì¹˜ í•„ìš”
    CUDA, cuDNN ìµœì‹  ë²„ì „ í•„ìš”
    GPU ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”

Scheduling:
SlurmQueues:
- Name: gpu-queue
ComputeResources:
- Name: gpu-compute
InstanceType: p5.48xlarge
MinCount: 0
MaxCount: 8
# DLAMI ì§€ì •
Image:
CustomAmi: ami-0a1b2c3d4e5f6g7h8  # DLAMI ID

ì£¼ì˜ ì‚¬í•­
# DLAMIë¥¼ ParallelClusterì™€ í•¨ê»˜ ì‚¬ìš© ì‹œ í˜¸í™˜ì„± í™•ì¸ í•„ìš”
# ParallelCluster ë²„ì „ê³¼ DLAMI OS ë²„ì „ ë§¤ì¹­ ì¤‘ìš”

# ì˜ˆ: ParallelCluster 3.xëŠ” Ubuntu 20.04/22.04, Amazon Linux 2 ì§€ì›

```



### Custom AMI
```
ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:

    íŠ¹ì • ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ì„ ìŠ¤ ì‚¬ì „ ì„¤ì¹˜
    íšŒì‚¬ ë‚´ë¶€ ë³´ì•ˆ ì •ì±… ì ìš©
    íŠ¹ìˆ˜í•œ ì»¤ë„ ì„¤ì • ë˜ëŠ” ë“œë¼ì´ë²„
    ë¶€íŒ… ì‹œê°„ ë‹¨ì¶• (ëª¨ë“  ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ì „ ì„¤ì¹˜)

# 1. ParallelCluster í‘œì¤€ AMI ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘
pcluster build-image \
--image-id my-custom-image \
--image-configuration image-config.yaml

# 2. ë˜ëŠ” ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ AMI ìƒì„±
aws ec2 create-image \
--instance-id i-1234567890abcdef0 \
--name "my-parallelcluster-custom-ami" \
--description "Custom AMI with pre-installed software"


Image:
Os: alinux2  # ë˜ëŠ” ubuntu2004, centos7 ë“±
CustomAmi: ami-custom123456

HeadNode:
Image:
CustomAmi: ami-custom-head123

Scheduling:
SlurmQueues:
- Name: compute
ComputeResources:
- Name: custom-nodes
Image:
CustomAmi: ami-custom-compute456

```




### í‘œì¤€ AMI + ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ (ìµœì‹  ê¶Œì¥ ë°©ì‹)
```
ë‹¨ê³„ 1: í´ëŸ¬ìŠ¤í„° ì„¤ì • íŒŒì¼ ì‘ì„±

cluster-config.yaml:
Region: us-east-1
Image:
Os: alinux2  # Amazon Linux 2

HeadNode:
InstanceType: c6i.xlarge
Networking:
SubnetId: subnet-12345678
Ssh:
KeyName: my-keypair
Iam:
AdditionalIamPolicies:
- Policy: arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess

Scheduling:
Scheduler: slurm
SlurmSettings:
ScaledownIdleTime: 10  # 10ë¶„ ìœ íœ´ í›„ ë…¸ë“œ ì¢…ë£Œ

SlurmQueues:
- Name: gpu-queue
CapacityType: ONDEMAND

ComputeResources:
- Name: p5-nodes
InstanceType: p5.48xlarge
MinCount: 0      # ìµœì†Œ ë…¸ë“œ ìˆ˜
MaxCount: 10     # ìµœëŒ€ ë…¸ë“œ ìˆ˜

# ğŸ”‘ í•µì‹¬: Enroot/Pyxis ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
CustomActions:
OnNodeConfigured:
Script: s3://my-bucket/scripts/install-enroot.sh
Args:
- arg1
- arg2

Networking:
SubnetIds:
- subnet-12345678
PlacementGroup:
Enabled: true  # ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ ìµœì í™”

SharedStorage:
- MountDir: /fsx
Name: fsx-storage
StorageType: FsxLustre
FsxLustreSettings:
StorageCapacity: 1200
DeploymentType: PERSISTENT_2

ë‹¨ê³„ 2: Enroot ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

s3://my-bucket/scripts/install-enroot.sh:
#!/bin/bash
# install-enroot.sh
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê° Compute Nodeê°€ ë¶€íŒ…ë  ë•Œ ìë™ ì‹¤í–‰ë¨

set -ex  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¤‘ë‹¨, ëª¨ë“  ëª…ë ¹ ì¶œë ¥

# ë¡œê·¸ íŒŒì¼ ì„¤ì •
LOGFILE="/var/log/enroot-install.log"
exec > >(tee -a ${LOGFILE})
exec 2>&1

echo "=========================================="
echo "Starting Enroot and Pyxis installation"
echo "Date: $(date)"
echo "Hostname: $(hostname)"
echo "=========================================="

# 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo "Installing prerequisites..."
yum install -y \
jq \
squashfs-tools \
parallel \
libnvidia-container-tools

# 2. Enroot ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜
echo "Installing Enroot..."
ENROOT_VERSION=3.4.1
cd /tmp

wget -q https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot-${ENROOT_VERSION}-1.x86_64.rpm
wget -q https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot+caps-${ENROOT_VERSION}-1.x86_64.rpm

yum install -y ./enroot-${ENROOT_VERSION}-1.x86_64.rpm
yum install -y ./enroot+caps-${ENROOT_VERSION}-1.x86_64.rpm

# 3. Enroot ì„¤ì •
echo "Configuring Enroot..."
mkdir -p /etc/enroot
cat > /etc/enroot/enroot.conf <<EOF
# Enroot ì„¤ì •
ENROOT_RUNTIME_PATH /run/enroot/user-\$(id -u)
ENROOT_CACHE_PATH /tmp/enroot-cache/user-\$(id -u)
ENROOT_DATA_PATH /tmp/enroot-data/user-\$(id -u)
ENROOT_TEMP_PATH /tmp
EOF

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ëª¨ë“  ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥)
mkdir -p /tmp/enroot-cache
chmod 1777 /tmp/enroot-cache

# 4. Pyxis ë¹Œë“œ ë° ì„¤ì¹˜
echo "Installing Pyxis..."
PYXIS_VERSION=0.16.1
cd /tmp

# Pyxis ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ
wget -q https://github.com/NVIDIA/pyxis/archive/refs/tags/v${PYXIS_VERSION}.tar.gz
tar xzf v${PYXIS_VERSION}.tar.gz
cd pyxis-${PYXIS_VERSION}

# Pyxis ë¹Œë“œ (Slurm ê²½ë¡œ ì§€ì •)
make install SLURM_DIR=/opt/slurm

# 5. Slurm plugstack ì„¤ì •
echo "Configuring Slurm plugstack for Pyxis..."

# plugstack ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /etc/slurm/plugstack.conf.d

# Pyxis í”ŒëŸ¬ê·¸ì¸ ì„¤ì • íŒŒì¼ ìƒì„±
cat > /etc/slurm/plugstack.conf.d/pyxis.conf <<EOF
required /usr/local/lib/slurm/spank_pyxis.so
EOF

# plugstack.confì— include ì¶”ê°€
PLUGSTACK_CONF="/opt/slurm/etc/plugstack.conf"
if [ ! -f "${PLUGSTACK_CONF}" ]; then
touch "${PLUGSTACK_CONF}"
fi

if ! grep -q "plugstack.conf.d" "${PLUGSTACK_CONF}"; then
echo "include /etc/slurm/plugstack.conf.d/*.conf" >> "${PLUGSTACK_CONF}"
fi

# 6. Slurm ë°ëª¬ ì¬ì‹œì‘
echo "Restarting Slurm daemon..."
systemctl restart slurmd

# 7. ì„¤ì¹˜ í™•ì¸
echo "Verifying installation..."

# Enroot ë²„ì „ í™•ì¸
if command -v enroot &> /dev/null; then
echo "âœ“ Enroot installed: $(enroot version)"
else
echo "âœ— Enroot installation failed"
exit 1
fi

# Pyxis í”ŒëŸ¬ê·¸ì¸ í™•ì¸
if [ -f /usr/local/lib/slurm/spank_pyxis.so ]; then
echo "âœ“ Pyxis plugin installed"
else
echo "âœ— Pyxis plugin installation failed"
exit 1
fi

# Slurm ìƒíƒœ í™•ì¸
if systemctl is-active --quiet slurmd; then
echo "âœ“ Slurmd is running"
else
echo "âœ— Slurmd is not running"
exit 1
fi

echo "=========================================="
echo "Enroot and Pyxis installation completed!"
echo "Date: $(date)"
echo "=========================================="

exit 0

ë‹¨ê³„ 3: S3ì— ìŠ¤í¬ë¦½íŠ¸ ì—…ë¡œë“œ
# ë¡œì»¬ì—ì„œ ì‹¤í–‰
aws s3 cp install-enroot.sh s3://my-bucket/scripts/install-enroot.sh

# ì‹¤í–‰ ê¶Œí•œ í™•ì¸ (ì„ íƒì‚¬í•­)
aws s3api put-object-acl \
--bucket my-bucket \
--key scripts/install-enroot.sh \
--acl bucket-owner-full-control

ë‹¨ê³„ 4: í´ëŸ¬ìŠ¤í„° ìƒì„±
# ParallelCluster ìƒì„±
pcluster create-cluster \
--cluster-name my-gpu-cluster \
--cluster-configuration cluster-config.yaml \
--region us-east-1

# ìƒì„± ìƒíƒœ ëª¨ë‹ˆí„°ë§
pcluster describe-cluster \
--cluster-name my-gpu-cluster \
--region us-east-1

# ì™„ë£Œ ëŒ€ê¸° (ì•½ 10-15ë¶„)
# Status: CREATE_COMPLETE í™•ì¸

ë‹¨ê³„ 5: Head Node ì ‘ì†
# SSH ì ‘ì†
pcluster ssh \
--cluster-name my-gpu-cluster \
--region us-east-1

# ë˜ëŠ” ì§ì ‘ SSH
ssh -i my-keypair.pem ec2-user@<head-node-ip>

ë‹¨ê³„ 6: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„

train.py (FSx Lustreì— ì €ì¥):
#!/usr/bin/env python3
# /fsx/scripts/train.py

import torch
import torch.distributed as dist
import os

def main():
# ë¶„ì‚° í™˜ê²½ ì´ˆê¸°í™”
dist.init_process_group(backend='nccl')

# Rank ì •ë³´
rank = dist.get_rank()
world_size = dist.get_world_size()
local_rank = int(os.environ['SLURM_LOCALID'])

# GPU ì„¤ì •
torch.cuda.set_device(local_rank)
device = torch.device(f'cuda:{local_rank}')

print(f"Rank {rank}/{world_size} - Local Rank {local_rank} - Device: {device}")

# ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
tensor = torch.ones(10).to(device) * (rank + 1)
print(f"Rank {rank} - Before all_reduce: {tensor}")

# All-Reduce í…ŒìŠ¤íŠ¸
dist.all_reduce(tensor, op=dist.ReduceOp.SUM)
print(f"Rank {rank} - After all_reduce: {tensor}")

# ì‹¤ì œ í•™ìŠµ ì½”ë“œëŠ” ì—¬ê¸°ì—...

# ì •ë¦¬
dist.destroy_process_group()

if __name__ == '__main__':
main()

ìŠ¤í¬ë¦½íŠ¸ ì—…ë¡œë“œ:
# Head Nodeì—ì„œ ì‹¤í–‰
mkdir -p /fsx/scripts
vi /fsx/scripts/train.py
# (ìœ„ ì½”ë“œ ë¶™ì—¬ë„£ê¸°)

chmod +x /fsx/scripts/train.py

ë‹¨ê³„ 7: ì‘ì—… ì œì¶œ ë° ì‹¤í–‰
# Head Nodeì—ì„œ ì‹¤í–‰

# ë°©ë²• 1: ì§ì ‘ srun ì‹¤í–‰
srun --partition=gpu-queue \
--nodes=4 \
--ntasks-per-node=8 \
--gpus-per-task=1 \
--container-image=nvcr.io/nvidia/pytorch:24.01-py3 \
--container-mounts=/fsx:/fsx \
python /fsx/scripts/train.py

# ë°©ë²• 2: sbatch ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
cat > submit_job.sh <<'EOF'
#!/bin/bash
#SBATCH --job-name=distributed-training
#SBATCH --partition=gpu-queue
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=8
#SBATCH --gpus-per-task=1
#SBATCH --time=02:00:00
#SBATCH --output=training_%j.out
#SBATCH --error=training_%j.err

# ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì§€ì •
export CONTAINER_IMAGE=nvcr.io/nvidia/pytorch:24.01-py3

# ì‘ì—… ì‹¤í–‰
srun --container-image=${CONTAINER_IMAGE} \
--container-mounts=/fsx:/fsx \
python /fsx/scripts/train.py
EOF

# ì‘ì—… ì œì¶œ
sbatch submit_job.sh

# ì‘ì—… ìƒíƒœ í™•ì¸
squeue
watch -n 1 squeue  # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

ë‹¨ê³„ 8: ì‹¤í–‰ ê³¼ì • ëª¨ë‹ˆí„°ë§
# í„°ë¯¸ë„ 1: ë…¸ë“œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
watch -n 2 'sinfo -N -l'

# í„°ë¯¸ë„ 2: ì‘ì—… ë¡œê·¸ í™•ì¸
tail -f training_*.out

# í„°ë¯¸ë„ 3: ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
# (Compute Nodeì— SSH ì ‘ì† í›„)
nvidia-smi -l 1


```





```

```





```

```
